import os
import streamlit as st
import google.generativeai as genai
import google.ai.generativelanguage as glm

# APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€
api_key = os.environ.get("GENERATIVEAI_API_KEY")

# APIã‚­ãƒ¼è¨­å®š
genai.configure(api_key=api_key)

# ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®šã™ã‚‹
st.set_page_config(
    page_title="Chat with Gemini 1.5Pro",
    page_icon="ğŸ¤–",
    layout="wide"  # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ã®ãŸã‚ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®š
)

st.title("ğŸ¤– Chat with Gemini 1.5Pro")

# ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®š
safety_settings = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_NONE"
    }
]

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "chat_session" not in st.session_state:
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    st.session_state["chat_session"] = model.start_chat(history=[
        glm.Content(role="user", parts=[glm.Part(text="ã‚ãªãŸã¯å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ã©ã®ã‚ˆã†ãªè©±é¡Œã‚‚é©åˆ‡ã«è©³ç´°ã«ç­”ãˆã¾ã™ã€‚æ™‚ã€…å‰äººã‚„å“²å­¦è€…ã®åè¨€ã‚’æ—¥æœ¬èªã§å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚")]),
        glm.Content(role="model", parts=[glm.Part(text="ã‚ã‹ã‚Šã¾ã—ãŸã€‚")])
    ])
    st.session_state["chat_history"] = []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å…¨ã¦è¡¨ç¤º
for message in st.session_state["chat_history"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›é€ä¿¡å¾Œå‡¦ç†
if prompt := st.chat_input("ã“ã“ã«å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # ãƒ¦ãƒ¼ã‚¶ã®å…¥åŠ›ã‚’è¡¨ç¤ºã™ã‚‹
    with st.chat_message("user"):
        st.markdown(prompt)

    # ãƒ¦ãƒ¼ã‚¶ã®å…¥åŠ›ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ ã™ã‚‹
    st.session_state["chat_history"].append({"role": "user", "content": prompt})

    # Genimi Proã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
    response = st.session_state["chat_session"].send_message(prompt, stream=True)

    # Genimi Proã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤ºï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
    with st.chat_message("assistant"):
        response_text_placeholder = st.empty()
        full_response_text = ""
        for chunk in response:
            full_response_text += chunk.text
            response_text_placeholder.markdown(full_response_text)

        # æœ€çµ‚çš„ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
        response_text_placeholder.markdown(full_response_text)

        # Genimi Proã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ ã™ã‚‹
        st.session_state["chat_history"].append({"role": "assistant", "content": full_response_text})

if __name__ == "__main__":
    from streamlit.web.cli import main
    from flask import Flask

    app = Flask(__name__)

    @app.route("/")
    def index():
        # Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹
        try:
            main()
        except SystemExit as e:
            if e.code != 0:
                return 'Error', 500
        except Exception as e:
            # ãã®ä»–ã®ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            return str(e), 500

        # æ­£å¸¸çµ‚äº†æ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
        return 'OK', 200

    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
